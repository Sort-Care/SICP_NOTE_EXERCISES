* Exercise
** 1.2
#+begin_src scheme
  (/ (+ 5 4 (- 2 (- 3 (+ 6 (/ 4 5)))))
     (* 3 (- 6 2) (- 2 7)))
#+end_src
** 1.3
Define a procedure that take three numbers as arguments and returns the sum of 
the squares of the two larger numbers.
#+begin_src scheme
  (define (square-sum-large-two a b c)
    (define (square-sum x y)
      (+ (* x x) (* y y)))
    (cond ((and (< c a) (< c b)) (square-sum a b))
          ((and (< a b) (< a c)) (square-sum b c))
          ((and (< b c) (< b a)) (square-sum a c))
          ((= a b) (square-sum b c))
          ((= a c) (square-sum a b))
          ((= b c) (square-sum a b))
          ))

  (square-sum-large-two 3 3 3)
#+end_src

#+RESULTS:
: 18
** 1.4
Observe that our model of evaluation allows for combinations whose operators are compound
expressions.
#+begin_src scheme
  (define (a-plus-abs-b a b)
    ((if (> b 0) + -) a b))
#+end_src
** 1.5
Determine whether interpreter is using applicative-order evaluation or normal-order
evaluation.
There are two procedures defined as follows:
#+begin_src scheme
  (define (p) (p))
  (define (test x y)
    (if (= x 0) 0 y))
  ;; then evaluate the expression
  (test 0 (p))
#+end_src
What behavior will be observed with an interpreter that uses applicative-order evaluation?
What behavior will be observed with an interpreter that uses normal-order evaluation?
(Assume that the evaluation rule for the special form ~if~ is the same for both cases:
the predicate expression is evaluated first, and the result determines whether to evaluate
the consequent or the alternative expression).

The normal-order will fully expand and notice the predicate is true and return 0;
However, the applicative-order will try to evaluate ~(p)~ first and apply that, but it is a
recursive call to ~(p)~ itself, so, following this rule, it ends up with an infinite loop.
** 1.6
Why ~if~ has to be a special form?
#+begin_src scheme
  (define (new-if predicate then-clause else-clause)
    (cond (predicate then-clause)
          (else else-clause)))
#+end_src
Delighted, Alyssa uses ~new-if~ to rewrite the square-root program:
#+begin_src scheme
  (define (sqrt-iter guess x)
    (new-if (good-enough? guess x)
            guess
            (sqrt-iter (improve guess x)
                       x)))
#+end_src
What happens when Alyssa attempts to use this to compute square roots? Explain.

Because the ~new-if~ is not a special form, so the subexpressions need to be evaluated before
we can apply the ~new-if~ to the operands. However, the third formal parameter is a recursive
call to ~sqrt-iter~, which will lead to infinite evaluation loop for sub-expressions. A dead loop.
** 1.7
The ~good-enough?~ test used in computing square roots will not be very effective for finding the square
roots of very small numbers.
Also, in real computers, arithmetic operations are almost always performed with limited precision.
This makes our test inadequate for very large numbers. Explain these statements, with examples showing
how the test fails for small and large numbers.

An alternative strategy for implementing ~good-enough?~ is to watch how guess changes from one iteration
to the next and to stop when the change is a very small fraction of the guess.

Design a square-root procedure that uses this kind of end test. Does this work better for small and large 

A: For very small numbers: assume $t$ is the tolerance we set for the ~good-enough?~ procedure, and
$\varepsilon$ is a very small number that is smaller than the tolerance we set.
When the guess approaches to a point where $guess^2 < (t + \varepsilon)$, than the absolute difference between 
$guess^2$ and $\varepsilon$ is always in the tolerance range but the $guess$ right now is not necessary the right 
answer.
Example (small number): Let $\varepsilon = 0.0000001$, start $guess$ from 1.0.


For very large numbers, what will happen if the arithmetic operations are performed with limited precision?
For large numbers, when the precision digits runs out, we might get stuck at a number which is not the
answer but we are not able to proceed because the ~good-enough?~ procedure is unable to tell the difference
because of precision overflow. Then the procedure will continue forever without convergence.
*** How floating-point numbers work
The idea is to compose a number of two main parts:
- A *significand* that contains the number's digits. Negative significands represent negative numbers.
- An *exponent* that says where the decimal (or binary) point is placed relative to the beginning of
  the significand. Negative exponents represent numbers that are very small (i.e. close to zero).
Such a format satisfies all the requirements:
+ It can represent numbers at wildly different magnitudes (limited by the length of the exponent)
+ It provides the same relative accuracy at all magnitudes (limited by the length of the significand)
+ It allows calculations across magnitudes: multiplying a very large and a very small number preserves 
  the accuracy of both in the result.

Decimal floating-point numbers usually take the form of a scientific notation with an explicit point
always between the 1st and 2nd digits.

Implementing it  another way:
#+begin_src scheme
  (define (sqrt x)
    (define tolerance 0.01) ;; when changed ratio is less than 1%
    (define (average a b) (/ (+ a b) 2))
    (define (good-enough? old-guess new-guess)
      (< (/ (abs (- old-guess new-guess)) ;; if the changed ration is smaller than tolerance
            old-guess)
         tolerance))
    (define (improve guess) ;; improve the guess
      (average (/ x guess) guess))
    (define (sqrt-iter guess) ;; iteration
      (if (good-enough? guess (improve guess)) ;; if further improving only changes a small ratio
          guess
          (sqrt-iter (improve guess))))
    (sqrt-iter 1.0))
(sqrt 3)
#+end_src

#+RESULTS:
: 1.7321428571428572
** 1.8
Replace the approximation of the square root procedure with:
$$
\frac{x/y^2 + 2y}{3}
$$
#+begin_src scheme
  (define (cubert x)
    (define tolerance 0.0001)
    (define good-enough?
      (lambda (guess)
        (< (abs (- (* guess guess guess)
                   x))
           tolerance)))
    (define improve
      (lambda (y)
        (/ (+ (/ x (* y y))
              (* 2 y))
           3)))
    (define cbrt-iter
      (lambda (guess)
        (if (good-enough? guess)
            guess
            (cbrt-iter (improve guess)))))
    (cbrt-iter 1.0))

(cubert 23)
#+end_src

#+RESULTS:
: 2.8438670109096598
** 1.9
Considering the following two procedure of adding numbers:
#+begin_src scheme
  ;; first procedure, recursive process
  (define (+ a b)
    (if (= a 0)
        b
        (inc (+ (dec a) b))))

  ;; second procedure, iterative process
  (define (+ a b)
    (if (= a 0)
        b
        (+ (dec a) (inc b))))
#+end_src
illustrate the process generated by each procedure in evaluating ~(+ 4 5)~
#+begin_src scheme
;; first one
(+ 4 5)
(inc (+ 3 5))
(inc (inc (+ 2 5)
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9

;; second one
(+ 4 5)
(+ (dec 4) (inc 5))
(+ 3 6)
(+ (dec 3) (inc 6))
(+ 2 7)
(+ (dec 2) (inc 7))
(+ 1 8)
(+ (dec 1) (inc 8))
(+ 0 9)
9
#+end_src
As we can see, the first procedure creates a recursive shape. While the second one creates
a iterative shape.

** 1.10
The following procedure computes a mathematical function called Armani's function:
#+begin_src scheme
  (define (A x y)
    (cond ((= y 0) 0)
          ((= x 0) (* 2 y))
          ((= y 1) 2)
          (else (A (- x 1)
                   (A x (- y 1))))))
(A 2 4)
#+end_src

#+RESULTS:
: 65536

What are the values of the following expressions?
#+begin_src scheme
(A 1 10)
(A 0 (A 1 9))
(A 0 (A 0 (A 1 8)))
(A 0 (A 0 (A 0 (A 1 7))))
;; ... 2 * 2 * 2 * ...
;; 2^10

(A 2 4)
(A 1 (A 2 3))
(A 1 (A 1 (A 2 2)))
(A 1 (A 1 (A 1 (A 2 1))))
(A 1 (A 1 (A 1 2)))
(A 1 (A 1 (A 0 (A 1 1))))
(A 1 (A 1 (A 0 2)))
(A 1 (A 1 4))
(A 1 (A 0 (A 1 3)))
(A 1 (A 0 8))
(A 1 16)
;; 2^16 = 2^{2^{4}}

(A 3 3)
;; 2^{2^{2^3}}
#+end_src

Consider the following procedures, where A is the procedure defined above:
#+begin_src scheme
(define (f n) (A 0 n)) ;; 2n

(define (g n) (A 1 n)) ;; 2^n

(define (h n) (A 2 n)) ;; 2^{2^n}

(define (k n) (* 5 n n))
#+end_src

Give concise mathematical definitions for the functions computed by the procedures ~f~, ~g~, and ~h~
for positive integer values of $n$. For example, ~(k, n)~ computes $5n^2$.
** 1.11
A function $f$ is defined as follows:

$$
f(n) = \begin{cases}
n &\text{if } n < 3\\
f(n-1) + 2f(n-2) + 3f(n-3) &\text{if } n \geq 3
\end{cases}
$$

Write a procedure that computes $f$ by means of an iterative process.
#+begin_src scheme
  (define (f n)
    (cond ((< n 3) n)
          (else (f-iter 1 2 3 (- n 3)))))

  (define (f-iter 1st 2ec 3rd count)
    (cond ((= count 0) 3rd)
          (else (f-iter 2ec
                        3rd
                        (+ (* 3 1st)
                           (* 2 2ec)
                           3rd)
                        (- count 1)))))

(f 7)
;; 1 2 3 10 (10+6+6)=22 
#+end_src

#+RESULTS:
: 22
** 1.12
The following pattern of numbers is Pascal's triangle.

\begin{tabular}{>{$n=}l<{$\hspace{12pt}}*{13}{c}}
0 &&&&&&&1&&&&&&\\
1 &&&&&&1&&1&&&&&\\
2 &&&&&1&&2&&1&&&&\\
3 &&&&1&&3&&3&&1&&&\\
4 &&&1&&4&&6&&4&&1&&\\
5 &&1&&5&&10&&10&&5&&1&\\
6 &1&&6&&15&&20&&15&&6&&1
\end{tabular}

Write a procedure that computes elements of Pascal's triangle by means of a recursive  process.

To accomplish this, let's first get a tabular form of the triangle in left-most alignment:

\begin{tabular}{>{$}l<{$}|*{7}{c}}
\multicolumn{1}{l}{$k$} &&&&&&&\\\cline{1-1} 
0 &1&&&&&&\\
1 &1&1&&&&&\\
2 &1&2&1&&&&\\
3 &1&3&3&1&&&\\
4 &1&4&6&4&1&&\\
5 &1&5&10&10&5&1&\\
6 &1&6&15&20&15&6&1\\\hline
\multicolumn{1}{l}{} &0&1&2&3&4&5&6\\\cline{2-8}
\multicolumn{1}{l}{} &\multicolumn{7}{c}{$i$}
\end{tabular}

The goal is to write a recursive procedure ~(pas-tri r c)~ that gives the number located at the
$r$ row and $c$ column in the Pascal's triangle.
#+begin_src scheme
  ;; notice that there are special cases
  ;; 1. at the edge
  ;; 2. at the top
  (define (pas-tri r c)
    (cond ((or (= r c)
               (= c 0))
           1)
          (else (+ (pas-tri (- r 1) ;; the line above
                            (- c 1));; the column to the left
                   (pas-tri (- r 1) ;; the line above
                            c)))))  ;; the same column
(pas-tri 6 4)
#+end_src

#+RESULTS:
: 15

** 1.13
Prove that $Fib(n)$ is the closest integer to $\phi^n / \sqrt{5}$, where $\phi = (1+\sqrt{5}) / 2$
Hint: Let $\psi = (1 - \sqrt{5}) / 2$. Use induction and the definition of the Fibonacci numbers to 
prove that $Fib(n) = (\phi^n - \psi^n) / \sqrt{5}$

1. Prove that $Fib(n) = (\phi^n - \psi^n) / \sqrt{5}$ by verifying for $n = 0, 1$, and use the $Fib(n) = Fib(n-1) + Fib(n-2)$
   equation to further prove it. Notice that $\phi^2 = \frac{3 + \sqrt{5}}{2}$ and 
   $\psi^2 = \frac{3 - \sqrt{5}}{2}$.
2. How to prove that $Fib(n)$ is the *closest* integer then?
   First it is an integer. And the difference between $Fib(n)$ and $\frac{\phi^n}{\sqrt{5}}$ is $\psi^n / \sqrt{5}$

$$
\frac{\psi^n}{\sqrt{5}} = \frac{(1-\sqrt{5})^n}{2^n\cdot\sqrt{5}}
$$

Next step is to prove the equation is actually smaller than $1/2$.
This can be proven by two observations:
1. $\psi$ itself is smaller than $1/2$. So $\psi^n$ must be much smaller than $1/2$.
2. $\sqrt{5}$ is bigger than 2
So dividing something that is clearly smaller than 1/2 by something that is bigger than
2 is going to produce a number that is less than 0.5.

That means the target $\phi^n / \sqrt{5}$ is apart from the integer $Fib(n)$ less than 0.5,
making $Fib(n)$ is the closest integer.

** 1.14
Draw the tree illustrating the process generated by the ~count-change~ procedure of section 1.2.2 in making change for 11 cents.
What are the orders of growth of the space and number of steps used by this process as the amount to be changed increases?

#+begin_src scheme
  (count-change 11)
  (cc 11 5)
  (+ (cc 11 4)
     (cc -39 5))

  (+ (+ (cc 11 3)
        (cc -14 4))     ;; 0
     0)

  (+ (+ (cc 11 3)
        0)
     0)

  (+ (+ (+ (cc 11 2)
           (cc 1 3)) ;; used a dime(10)
        0)
     0)

  (+ (+ (+ (+ (cc 11 1)     ;; change 11 cents merely with 1 cent coins
              (cc 6 2))     ;; used a nickle, 6 cents to go with last two types
           (+ (cc 1 2)      ;; doing the rest 1 cent with two types of coins
              (cc -9 3)))   ;; 0
        0)
     0)

  (+ (+ (+ (+ (+ (cc 11 0)
                 (cc 10 1)) ;; used one cent
              (+ (cc 6 1)   ;; used a nickle, try no more nickles solution
                 (cc 1 2))) ;; used another nickle, 1 cent left to change
           (+ (+ (cc 1 1)   ;; doing the rest 1 cent with only one type of coins
                 (cc -4 2)) ;; 0
              0))
        0)
     0)

  (+ (+ (+ (+ (+ (cc 11 0)
                 (cc 10 1)) ;; used one cent
              (+ (cc 6 1)   ;; used a nickle, try no more nickles solution
                 (cc 1 2))) ;; used another nickle, 1 cent left to change
           (+ (+ 1          ;; only one way to do 1 cent with 1 cent coins
                 0)         ;; 0
              0))
        0)
     0)

  (+ (+ (+ (+ (+ 0
                 (+ (cc 10 0)  ;; 0
                    (cc 9 1))) ;; used the second cent
              (+ (+ (cc 6 0)   ;; 0
                    (cc 5 1))  ;; used a nickle, one cent, try more cents
                 (+ (cc 1 1)   ;; one cent with one cent coins => 1
                    (cc -4 2)))) ;; used two nickles, trying third, fail
           (+ 1
              0))
        0)
     0)
#+end_src

This procedure creates a tree-recursive structure, and the branching factor is 2.
The deepest branch goes $O(n)$ steps down, where $n$ is the money to change.
So the process takes $O(2^n)$ steps to finish and $O(n)$ space to run.
** 1.15
The sine of an angle (specified in radians) can be computed by making use of the approximation 
$\sin{x}\approx x$ if $x$ is sufficiently small, and the trigonometric identity:

$$
\sin{x} = 3 \sin{\frac{x}{3}} - 4\sin^3{\frac{x}{3}}
$$

to reduce the size of the argument of $sin$. (For purposes of this exercise an angle is considered "sufficiently small" if its
magnitude is not greater than 0.1 radians.)
These ideas are incorporated in the following procedures:
#+begin_src scheme
  (define (cube x) (* x x x))

  (define (p x) (- (* 3 x) (* 4 (cube x))))

  (define (sine angle)
    (if (not (> (abs angle) 0.1))
        angle
        (p (sine (/ angle 3.0)))))
#+end_src

1. How many times is the procedure ~p~ applied when ~(sine 12.15)~ is evaluated?
   $12.5 / 3^x \leq 0.1$
   By solving the equation above, we get $x\geq5$, thus ~p~ is applied 5 times.

2. What is the order of growth in space and number of steps (as a function of $a$) used by the process
   generated by the $sine$ procedure when ~(sine a)~ is evaluated?
   The order of growth in number of steps is $O(\log_3a)$.
   The order of growth in space is $O(1)$.
** 1.16
Design a procedure that evolves an *iterative* exponentiation process that uses successive
squaring and uses a logarithmic number of steps, as does ~fast-expt~.
Hint: use the observation that $(b^{n/2})^2 = (b^2)^{n/2}$, keep, along with the exponent $n$
and the base $b$, an additional state variable $a$, and define the state transformation in 
such a way that the product $ab^n$ is unchanged from state to state.
At the beginning of the process $a$ is taken to be 1, and the answer is given by the value 
of $a$ at the end of the process.
In general, the technique of defining an **invariant quantity** that remains unchanged from state
to state is a powerful way to think about the design of iterative algorithms.

IDEA: Iteratively, take the exponent inside and replace old base with new ones, until outer 
exponent is 1.
When the outer exponent left is even, further the process by making $a\Leftarrow a^2$ and 
thus shrink the exponent by dividing it by 2.
When the outer exponent is odd, take 1 away and make $a\Leftarrow ab$, shrink the exponent by 1.

The above idea is terribly wrong! Because the case for dealing with odd exponent is problematic.
The "1" taken out is not on the base of $b$, but rather on the base of what is inside right now.
Can we put another variable that hold what's outside?
#+begin_src scheme
  (define (expt b n) ;; expect b and n both to be integers.
    (expt-iter b n b 1))

  ;; outer is for keep track of what is outside.
  (define (expt-iter b cnt a outer)
    (cond ((= cnt 0) 1)
          ((= cnt 1) (* a outer))
          ((even? cnt) (expt-iter b
                                  (/ cnt 2)  ;; divide the outside expo by 2
                                  (square a) ;; double the inside
                                  outer))    ;; outside additional remains the same
          (else (expt-iter b
                           (- cnt 1)         ;; minus 1 to make it even
                           a                 ;; inside remains the same
                           (* outer a)))))   ;; outer additional get multiplied by the base

  (define (even? x)
    (= (remainder x 2) 0))

  (define (square x) (* x x))

(expt 2 19)
#+end_src

#+RESULTS:
: 524288

This solution I have here does not follow the hint given in the book. I haven't figured out how 
to compute it with an /invariant quantity/.
** 1.17
The exponentiation algorithms in this section are based on performing exponentiation by means 
of repeated multiplication. In a similar way, one can perform integer multiplication by means
of repeated addition. The following multiplication procedure (in which it is assumed that our 
language can only add, not multiply) is analogous to the ~expt~ procedure:
#+begin_src scheme
  (define (* a b)
    (if (= b 0)
        0
        (+ a (* a (- b 1)))))
#+end_src
This algorithm takes a number of steps that is linear in $b$. Now suppose we include, together with
addition, operations ~double~, which doubles the integer, and ~halve~, which divides an (even) integer
by 2. Using these, design a multiplication procedure analogous to ~fast-expt~ that uses a logarithmic
number of steps.

#+begin_src scheme
  (define (double x) (+ x x))
  (define (halve x) (/ x 2))
  (define (even? x)
    (= (remainder x 2)
       0))

  (define (fast-mul a b)
    (cond ((= b 0) 0)
          ((even? b) (fast-mul (double a)
                               (halve b)))
          (else (+ a
                   (fast-mul a
                             (- b 1))))))
#+end_src
** 1.18
Using the results of exercises 1.16 and 1.17, devise a procedure that generates an iterative process
for multiplying two integers in terms of adding, doubling, and halving and uses a logarithmic number
of steps.
#+begin_src scheme
  (define (double x) (+ x x))
  (define (halve x) (/ x 2))
  (define (even? x) (= (remainder x 2) 0))

  (define (fast-mul a b)
    (mul-iter a b 0))

  (define (mul-iter a b add)
    (cond ((= b 0) 0)
          ((= b 1) (+ a add))
          ((even? b) (mul-iter (double a)
                               (halve b) ;; logarithmic
                               add))
          (else (mul-iter a
                          (- b 1)
                          (+ add a)))))  ;; carry the information along, makes it an iterative process
(fast-mul 23 59)
#+end_src

#+RESULTS:
: 1357

** 1.19
There is a clever algorithm for computing the Fibonacci numbers in logarithmic
numbers of steps. Recall the transformation of the state variables $a$ and $b$
in the ~fib-iter~ process of section 1.2.2:
 
\begin{align*}
a &\leftarrow a + b\\
b &\leftarrow a
\end{align*}

Call this transformation $T$, and observe that applying $T$ over and over again
$n$ times, starting with 1 and 0, produces the pair $Fib(n+1)$ and $Fib(n)$.
In other words, the Fibonacci numbers are produced by $T^n$, the $n$th power
or the transformation $T$, starting with the pair $(1,0)$.

Now consider the $T$ to be the special case of $p = 0$ and $q = 1$ in a family
of transformations $T_{pq}$, where $T_{pq}$ transforms the pair $(a,b)$ according
to:

\begin{align*}
a &\leftarrow bq + aq + ap \\
b &\leftarrow bp + aq
\end{align*}

Show that if we apply such transformation $T_{pq}$ twice, the effect is the same
as using a single transformation $T_{p^\prime q^\prime}$ of the same form, and compute $p^\prime$
and $q^\prime$ in terms of $p$ and $q$.

This gives us an explicit way to square these transformations, and thus we can
compute $T^n$ using successive squaring, as in the ~fast-expt~ procedure. Put
this all together to complete the following procedure, which runs in a logarithmic 
number of steps:

#+begin_src scheme
  (define (fib n)
    (fib-iter 1 0 0 1 n))

  (define (fib-iter a b p q count)
    (cond ((= count 0) b)
          ((even? count)
           (fib-iter a
                     b
                     (+ (square p) (square q))
                     (+ (square q) (* 2 p q))
                     (/ count 2)))
          (else (fib-iter (+ (* b q) (* a q) (* a p))
                          (+ (* b p) (* a q))
                          p
                          q
                          (- count 1)))))

  (define (even? x) (= (remainder x 2) 0))
  (define (square x) (* x x))

(fib 13)
#+end_src

#+RESULTS:
: 233



** 1.20
The process that a procedure generates is of course independent on the rules used by the
interpreter. As an example, consider the iterative ~gcd~ procedure given in text book.
Suppose we were to interpret this procedure using normal-order evaluation, as discussed in 
section 1.1.5. (The normal-order-evaluation rule for ~if~ is described in exercise 1.5.)
Using the substitution method (for normal order), illustrate the process generated in 
evaluating ~(gcd 206 40)~ and indicate the ~remainder~ operations that are actually performed.
How many ~remainder~ operations are actually performed in the normal-order evaluation of
~(gcd 206 40)~? In the applicative-order evaluation?

Review that applicative-order will evaluate the operands whenever possible, and then
apply the operator to the operands.
However, normal order will delay any evaluation to a point where something has to be
evaluated to proceed. In this exercise, the normal order will only evaluate expressions
either when: 1) fully expanded, 2) ~if~ special form's predicate needs to be evaluated
to decide which clause (the consequent or the alternative) to expand next.

For applicative-order, ~remainder~ gets evaluated 4 times as it shows here:
#+begin_src scheme
(gcd 206 40)
;;   |
;;   v
(gcd 40 (remainder 206 40)) ;; 1 (remainder eval counter)
(gcd 40 6)
;;   |
;;   v
(gcd 6 (remainder 40 6))    ;; 2
(gcd 6 4)
;;   |
;;   v
(gcd 4 (remainder 6 4))     ;; 3
(gcd 4 2)
;;   |
;;   v
(gcd 2 (remainder 4 2))     ;; 4
(gcd 2 0)                   ;; predicate is true, stop and return 2
#+end_src

For normal-order evaluation:
#+begin_src scheme
  (gcd 206 40)
  (if (= 40 0) ...)
  (gcd 40 (remainder 206 40))

  (if (= (remainder 206 40) 0) ...)                               ;; 1
  ;; 6, not 0
  (gcd (remainder 206 40)
       (remainder 40
                  (remainder 206 40)))

  (if (= (remainder 40                                            ;; 1 +2
                    (remainder 206 40))
         0) ...)
  ;;40%6 = 4, not 0

  (gcd (remainder 40
                  (remainder 206 40))               ;; a
       (remainder (remainder 206 40)
                  (remainder 40
                             (remainder 206 40))))  ;; b

  (if (= (remainder (remainder 206 40)                             ;; 1 +2 +4
                    (remainder 40
                               (remainder 206 40))) ;; b == 0?
         0) ...)
  ;; 2, not zero

  (gcd (remainder (remainder 206 40)
                  (remainder 40
                             (remainder 206 40)))   ;; a
       (remainder (remainder 40
                             (remainder 206 40))
                  (remainder (remainder 206 40)
                             (remainder 40
                                        (remainder 206 40))))) ;; b
  (if (= (remainder (remainder 40                                   ;; 1 +2 +4 +7 = 14
                               (remainder 206 40))
                    (remainder (remainder 206 40)
                               (remainder 40
                                          (remainder 206 40)))) ;; 4%2 = 0
         0) ...)

  (remainder (remainder 206 40)
             (remainder 40
                        (remainder 206 40))) ;; fully expanded, evaluate all rest expressions
  ;; finally, 14 + 4 = 18
  ;; So the remainder get evaluated 18 times in total.
  ;; FORMULA?
#+end_src

Notice that, the changing of numbers of ~remainder~ appearing in the two operands of ~gcd~ obeys
the following pattern:

\begin{align*}
(R_a,R_b) &\rightarrow \text{Occurance of remainder procedure}\\
(0, 0)     &\rightarrow  \text{None}   \\
(0, 1)     &\rightarrow 1+(0+0)=1          \\
(1, 2)     &\rightarrow 1+(0+1)=2          \\
(2, 4)     &\rightarrow 1+(1+2)=4          \\
(4, 7)     &\rightarrow 1+(2+4)=7          \\
4          &\rightarrow \text{predicate true, evaluate }a
\end{align*}

Assume our iteration starts from 0. For simplicity, we consider when applying ~gcd~, the 
two operands $a$ and $b$ are generated by last iteration in the alternate clause.
The 1 that appears in each line is the new ~remainder~ that kicks in in the alternative clause.
And the addition between the parentheses means using the operand $a$ and $b$ from previous iteration
are used as new operands for the new ~remainder~ procedure.

First off, we mainly evaluate ~remainder~ when in the ~if~ predicate. Each time,
when we forward one iteration, the number of ~remainder~ in $b$ from last iteration is evaluated,
to determine which clause to expand next.
That is: $0+1+2+4+7$ in this example. Generally, the predicate evaluation will not stop
until in the final iteration, where $b$ equals to 0. When that happens, all the things in $a$ got
evaluated.

To formulate it, lets assume $(R_a^{\langle i \rangle}, R_b^{\langle i \rangle})$ 
is a pair of integers that record how many times ~remainder~ is invoked 
in $a$ and $b$ during $i$ th iteration, starting from 0.
Say $k$ is the final iteration where $b^{\langle k-1 \rangle}=0$.
Then the total times that ~remainder~ gets evaluated is:

$$
T(remainder) = R_b^{\langle 0 \rangle} + R_b^{\langle 1 \rangle} + R_b^{\langle 2 \rangle} + \cdots + R_b^{\langle k-1 \rangle} + R_a^{\langle k-1 \rangle}
$$

Notice that,
$$
R_b^{\langle i \rangle} = R_a^{\langle i+1 \rangle} = \sum_{j = 0}^i Fib(j)
$$

Thus the formula can be rewritten into:

$$
T(remainder) = \sum_{j = 0}^0 Fib(j) + \sum_{j = 0}^1 Fib(j) + \sum_{j = 0}^2 Fib(j) + \cdots + 2\sum_{j = 0}^{k-2} Fib(j) + \sum_{j = 0}^{k-1} Fib(j)
$$
